# basic_airflow_project
This project explains about how to create a basic data pipeline using Airflow as an orchestrator for all the data tasks

## Pre-Requisite
Plese keep the airflow installation ready with docker and then perform this tasks

## Installation
Create virtual environment for python 3.8

```bash
  conda create -n <environment-name> python=3.8 -y
```
Enter the virtual environment
```bash
    activate <environment-name>
```
install all dependencies of the this project by 
```bash
  pip install -r requirements.txt
```

## airflow screenshots
![image](https://user-images.githubusercontent.com/52929512/234046965-8482d15d-3821-4e9b-8501-8b2655bc2506.png)

